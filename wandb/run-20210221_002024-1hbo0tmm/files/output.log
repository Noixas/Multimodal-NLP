21/02/2021 12:20:25 AM : INFO - Data path checked..
21/02/2021 12:20:25 AM : INFO - Model save path checked..
21/02/2021 12:20:25 AM : INFO - config JSON path checked..

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Running training with the following parameters: 
21/02/2021 12:20:25 AM : INFO - Tensorboard Visualization path checked..
21/02/2021 12:20:25 AM : INFO - Cleaning Visualization path of older tensorboard files...


data_path : ./dataset
model_path : ./model_checkpoints
vis_path : ./vis_checkpoints
model_save_name : meme.pt
no_model_checkpoints : False
remove_checkpoints : False
config : config/uniter-base.json
feature_path : ./dataset/own_features
pretrained_model_file : uniter-base.pt
max_txt_len : 60
max_bb : 100
min_bb : 10
num_bb : 36
optimizer : adam
loss_func : bce_logits
optimize_for : aucroc
scheduler : warmup_cosine
beta1 : 0.9
beta2 : 0.999
batch_size : 16
num_workers : 0
gradient_accumulation : 2
max_grad_norm : 5
pos_wt : 1
lr : 3e-05
warmup_steps : 500
weight_decay : 0.001
max_epoch : 30
lr_decay_step : 3
lr_decay_factor : 0.8
patience : 5.0
early_stop_thresh : 0.001
seed : 43
log_every : 2000
fc_dim : 64
dropout : 0.2
filter_text : True
normalize_img : True
train_filename : upsampled_1_train.jsonl
device : cuda
n_classes : 1

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
filter text True
filter text True
filter text True
21/02/2021 12:20:36 AM : INFO - Using pretrained UNITER base model ./model_checkpoints/uniter-base.pt
21/02/2021 12:20:36 AM : INFO - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

MemeUniter
MemeUniter(
  (uniter_model): UniterModel(
    (embeddings): UniterTextEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (img_embeddings): UniterImageEmbeddings(
      (img_linear): Linear(in_features=2048, out_features=768, bias=True)
      (img_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_linear): Linear(in_features=7, out_features=768, bias=True)
      (mask_embedding): Embedding(2, 2048, padding_idx=0)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): UniterEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (linear): Linear(in_features=768, out_features=1, bias=True)
)


====================================================================================================
					 Training Network
====================================================================================================

Beginning training at:  2021-02-21 00:20:39.769155 


Epoch: 1/30,            
train_loss = 0.5798,  train_acc = 0.6780,  train_prec = 0.8045,  train_recall = 0.7146,  train_f1 = 0.7569,  train_aucroc = 0.7270,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.6985,  eval_acc = 0.6320,  eval_prec = 0.3968,  eval_recall = 0.7368,  eval_f1 = 0.5158,  eval_aucroc = 0.7045,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002730
Elapsed Time:  00:04:29.3021/02/2021 12:25:09 AM : INFO - New High Score! Saving model...

21/02/2021 12:25:10 AM : INFO - current patience: 0

Epoch: 2/30,            
train_loss = 0.3256,  train_acc = 0.8677,  train_prec = 0.9086,  train_recall = 0.8825,  train_f1 = 0.8953,  train_aucroc = 0.9274,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.8108,  eval_acc = 0.6640,  eval_prec = 0.5344,  eval_recall = 0.7135,  eval_f1 = 0.6111,  eval_aucroc = 0.7252,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002998
Elapsed Time:  00:08:55.7921/02/2021 12:29:35 AM : INFO - New High Score! Saving model...

21/02/2021 12:29:36 AM : INFO - current patience: 0

Epoch: 3/30,            
train_loss = 0.1534,  train_acc = 0.9485,  train_prec = 0.9654,  train_recall = 0.9525,  train_f1 = 0.9589,  train_aucroc = 0.9816,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.0020,  eval_acc = 0.6720,  eval_prec = 0.5506,  eval_recall = 0.7196,  eval_f1 = 0.6239,  eval_aucroc = 0.7057,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002992
Elapsed Time:  00:13:26.4021/02/2021 12:34:06 AM : INFO - current patience: 1


Epoch: 4/30,            
train_loss = 0.0924,  train_acc = 0.9707,  train_prec = 0.9795,  train_recall = 0.9737,  train_f1 = 0.9766,  train_aucroc = 0.9925,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3277,  eval_acc = 0.6660,  eval_prec = 0.4372,  eval_recall = 0.7941,  eval_f1 = 0.5640,  eval_aucroc = 0.7308,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002982
Elapsed Time:  00:17:50.3221/02/2021 12:38:30 AM : INFO - New High Score! Saving model...

21/02/2021 12:38:31 AM : INFO - current patience: 0

Epoch: 5/30,            
train_loss = 0.0708,  train_acc = 0.9770,  train_prec = 0.9828,  train_recall = 0.9804,  train_f1 = 0.9816,  train_aucroc = 0.9958,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4449,  eval_acc = 0.6540,  eval_prec = 0.4089,  eval_recall = 0.7891,  eval_f1 = 0.5387,  eval_aucroc = 0.7274,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002968
Elapsed Time:  00:22:15.0221/02/2021 12:42:54 AM : INFO - current patience: 1


Epoch: 6/30,            
train_loss = 0.0714,  train_acc = 0.9769,  train_prec = 0.9823,  train_recall = 0.9806,  train_f1 = 0.9815,  train_aucroc = 0.9957,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4246,  eval_acc = 0.6640,  eval_prec = 0.4615,  eval_recall = 0.7651,  eval_f1 = 0.5758,  eval_aucroc = 0.7344,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002949
Elapsed Time:  00:26:34.9721/02/2021 12:47:14 AM : INFO - New High Score! Saving model...

21/02/2021 12:47:16 AM : INFO - current patience: 0

Epoch: 7/30,            
train_loss = 0.0602,  train_acc = 0.9807,  train_prec = 0.9847,  train_recall = 0.9844,  train_f1 = 0.9845,  train_aucroc = 0.9968,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3813,  eval_acc = 0.6620,  eval_prec = 0.4575,  eval_recall = 0.7635,  eval_f1 = 0.5722,  eval_aucroc = 0.7339,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002926
Elapsed Time:  00:30:59.9021/02/2021 12:51:39 AM : INFO - current patience: 1


Epoch: 8/30,            
train_loss = 0.0644,  train_acc = 0.9784,  train_prec = 0.9844,  train_recall = 0.9810,  train_f1 = 0.9827,  train_aucroc = 0.9971,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6572,  eval_acc = 0.6320,  eval_prec = 0.3522,  eval_recall = 0.7838,  eval_f1 = 0.4860,  eval_aucroc = 0.7140,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002899
Elapsed Time:  00:35:21.0721/02/2021 12:56:00 AM : INFO - current patience: 2


Epoch: 9/30,            
train_loss = 0.0649,  train_acc = 0.9789,  train_prec = 0.9849,  train_recall = 0.9813,  train_f1 = 0.9831,  train_aucroc = 0.9968,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4215,  eval_acc = 0.6340,  eval_prec = 0.4656,  eval_recall = 0.6928,  eval_f1 = 0.5569,  eval_aucroc = 0.7075,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002868
Elapsed Time:  00:39:43.7521/02/2021 01:00:23 AM : INFO - current patience: 3


Epoch: 10/30,            
train_loss = 0.0606,  train_acc = 0.9800,  train_prec = 0.9856,  train_recall = 0.9823,  train_f1 = 0.9840,  train_aucroc = 0.9973,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6769,  eval_acc = 0.6320,  eval_prec = 0.3603,  eval_recall = 0.7739,  eval_f1 = 0.4917,  eval_aucroc = 0.7160,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002834
Elapsed Time:  00:44:10.8121/02/2021 01:04:50 AM : INFO - current patience: 4


Epoch: 11/30,            
train_loss = 0.0532,  train_acc = 0.9827,  train_prec = 0.9876,  train_recall = 0.9847,  train_f1 = 0.9862,  train_aucroc = 0.9979,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.8463,  eval_acc = 0.6480,  eval_prec = 0.4332,  eval_recall = 0.7483,  eval_f1 = 0.5487,  eval_aucroc = 0.7006,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002795
Elapsed Time:  00:48:34.46
21/02/2021 01:09:14 AM : INFO - current patience: 5

----------------------------------------------------------------------------------------------------

--------------------------------------------------
Best Validation scores:
--------------------------------------------------

Val accuracy of best model = 66.400
Val AUC-ROC of best model = 73.441
Val precision of best model = 46.154
Val recall of best model = 76.510
Val f1 of best model = 57.576

21/02/2021 01:09:14 AM : INFO - Training terminated early because the Validation aucroc did not improve for  5.0  epochs
--------------------------------------------------
		Evaluating on test set
--------------------------------------------------
21/02/2021 01:09:14 AM : INFO - Using UNITER model ./model_checkpoints/meme.pt
21/02/2021 01:09:15 AM : INFO - Exporting dev_seen predictions...
21/02/2021 01:09:18 AM : INFO - Finished export of dev_seen predictions
21/02/2021 01:09:18 AM : INFO - Optimal threshold on validation dataset: 0.5000 (accuracy=66.40%)
21/02/2021 01:09:18 AM : INFO - Export and testing on test_seen...
21/02/2021 01:09:24 AM : INFO - Finished export of test predictions
