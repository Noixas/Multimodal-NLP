
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Running training with the following parameters: 
20/02/2021 11:23:01 PM : INFO - Data path checked..

data_path : ./dataset
model_path : ./model_checkpoints
vis_path : ./vis_checkpoints
model_save_name : meme.pt
no_model_checkpoints : False
remove_checkpoints : False
config : config/uniter-base.json
feature_path : ./dataset/own_features
pretrained_model_file : uniter-base.pt
max_txt_len : 60
max_bb : 100
min_bb : 10
num_bb : 36
optimizer : adam
loss_func : bce_logits
optimize_for : aucroc
scheduler : warmup_cosine
beta1 : 0.9
beta2 : 0.999
batch_size : 16
num_workers : 0
gradient_accumulation : 2
max_grad_norm : 5
20/02/2021 11:23:01 PM : INFO - Model save path checked..
20/02/2021 11:23:01 PM : INFO - config JSON path checked..
20/02/2021 11:23:01 PM : INFO - Tensorboard Visualization path checked..
20/02/2021 11:23:01 PM : INFO - Cleaning Visualization path of older tensorboard files...

pos_wt : 1
lr : 3e-05
warmup_steps : 500
weight_decay : 0.001
max_epoch : 30
lr_decay_step : 3
lr_decay_factor : 0.8
patience : 5.0
early_stop_thresh : 0.001
seed : 43
log_every : 2000
fc_dim : 64
dropout : 0.2
filter_text : True
normalize_img : True
train_filename : upsampled_train.jsonl
device : cuda
n_classes : 1

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
filter text True
filter text True
filter text True
20/02/2021 11:23:14 PM : INFO - Using pretrained UNITER base model ./model_checkpoints/uniter-base.pt
20/02/2021 11:23:14 PM : INFO - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

MemeUniter
MemeUniter(
  (uniter_model): UniterModel(
    (embeddings): UniterTextEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (img_embeddings): UniterImageEmbeddings(
      (img_linear): Linear(in_features=2048, out_features=768, bias=True)
      (img_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_linear): Linear(in_features=7, out_features=768, bias=True)
      (mask_embedding): Embedding(2, 2048, padding_idx=0)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): UniterEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (linear): Linear(in_features=768, out_features=1, bias=True)
)


====================================================================================================
					 Training Network
====================================================================================================

Beginning training at:  2021-02-20 23:23:18.152330 


Epoch: 1/30,            
train_loss = 0.4320,  train_acc = 0.8438,  train_prec = 0.0146,  train_recall = 0.4074,  train_f1 = 0.0281,  train_aucroc = 0.5916,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.9682,  eval_acc = 0.5220,  eval_prec = 0.0364,  eval_recall = 0.9000,  eval_f1 = 0.0700,  eval_aucroc = 0.5801,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00003000
Elapsed Time:  00:05:45.0020/02/2021 11:29:03 PM : INFO - New High Score! Saving model...

20/02/2021 11:29:04 PM : INFO - current patience: 0

Epoch: 2/30,            
train_loss = 0.3934,  train_acc = 0.8498,  train_prec = 0.0990,  train_recall = 0.5956,  train_f1 = 0.1698,  train_aucroc = 0.6988,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.9094,  eval_acc = 0.5380,  eval_prec = 0.0810,  eval_recall = 0.8333,  eval_f1 = 0.1476,  eval_aucroc = 0.6451,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002997
Elapsed Time:  00:11:28.8320/02/2021 11:34:46 PM : INFO - New High Score! Saving model...

20/02/2021 11:34:48 PM : INFO - current patience: 0

Epoch: 3/30,            
train_loss = 0.3064,  train_acc = 0.8795,  train_prec = 0.4078,  train_recall = 0.6881,  train_f1 = 0.5121,  train_aucroc = 0.8508,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.9651,  eval_acc = 0.6020,  eval_prec = 0.2429,  eval_recall = 0.8333,  eval_f1 = 0.3762,  eval_aucroc = 0.7043,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002990
Elapsed Time:  00:17:14.6020/02/2021 11:40:32 PM : INFO - New High Score! Saving model...

20/02/2021 11:40:34 PM : INFO - current patience: 0

Epoch: 4/30,            
train_loss = 0.2182,  train_acc = 0.9209,  train_prec = 0.6515,  train_recall = 0.8015,  train_f1 = 0.7188,  train_aucroc = 0.9232,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.9091,  eval_acc = 0.6440,  eval_prec = 0.3887,  eval_recall = 0.7805,  eval_f1 = 0.5189,  eval_aucroc = 0.7179,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002979
Elapsed Time:  00:23:10.7020/02/2021 11:46:28 PM : INFO - New High Score! Saving model...

20/02/2021 11:46:30 PM : INFO - current patience: 0
20/02/2021 11:52:14 PM : INFO - current patience: 1

Epoch: 5/30,            
train_loss = 0.1506,  train_acc = 0.9481,  train_prec = 0.7976,  train_recall = 0.8575,  train_f1 = 0.8265,  train_aucroc = 0.9636,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.0558,  eval_acc = 0.6000,  eval_prec = 0.3239,  eval_recall = 0.7080,  eval_f1 = 0.4444,  eval_aucroc = 0.6707,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002963
Elapsed Time:  00:28:56.29
20/02/2021 11:58:02 PM : INFO - current patience: 2

Epoch: 6/30,            
train_loss = 0.1121,  train_acc = 0.9622,  train_prec = 0.8566,  train_recall = 0.8954,  train_f1 = 0.8756,  train_aucroc = 0.9782,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.5057,  eval_acc = 0.6100,  eval_prec = 0.4170,  eval_recall = 0.6688,  eval_f1 = 0.5137,  eval_aucroc = 0.6975,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002944
Elapsed Time:  00:34:44.84

Epoch: 7/30,            
train_loss = 0.0838,  train_acc = 0.9728,  train_prec = 0.8937,  train_recall = 0.9284,  train_f1 = 0.9107,  train_aucroc = 0.9869,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4690,  eval_acc = 0.6460,  eval_prec = 0.4291,  eval_recall = 0.7465,  eval_f1 = 0.5450,  eval_aucroc = 0.6994,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002920
Elapsed Time:  00:40:32.1021/02/2021 12:03:50 AM : INFO - current patience: 3


Epoch: 8/30,            
train_loss = 0.0656,  train_acc = 0.9791,  train_prec = 0.9248,  train_recall = 0.9398,  train_f1 = 0.9322,  train_aucroc = 0.9906,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.5555,  eval_acc = 0.6460,  eval_prec = 0.4575,  eval_recall = 0.7244,  eval_f1 = 0.5608,  eval_aucroc = 0.6949,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002892
Elapsed Time:  00:46:24.69
21/02/2021 12:09:42 AM : INFO - current patience: 4

Epoch: 9/30,            
train_loss = 0.0616,  train_acc = 0.9808,  train_prec = 0.9258,  train_recall = 0.9494,  train_f1 = 0.9374,  train_aucroc = 0.9927,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.9691,  eval_acc = 0.6200,  eval_prec = 0.3684,  eval_recall = 0.7280,  eval_f1 = 0.4892,  eval_aucroc = 0.6867,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002861
Elapsed Time:  00:52:16.1421/02/2021 12:15:34 AM : INFO - current patience: 5


----------------------------------------------------------------------------------------------------

--------------------------------------------------
Best Validation scores:
--------------------------------------------------

Val accuracy of best model = 64.400
Val AUC-ROC of best model = 71.788
Val precision of best model = 38.866
Val recall of best model = 78.049
Val f1 of best model = 51.892

--------------------------------------------------
		Evaluating on test set
--------------------------------------------------
21/02/2021 12:15:34 AM : INFO - Training terminated early because the Validation aucroc did not improve for  5.0  epochs
21/02/2021 12:15:34 AM : INFO - Using UNITER model ./model_checkpoints/meme.pt
21/02/2021 12:15:35 AM : INFO - Exporting dev_seen predictions...
21/02/2021 12:15:38 AM : INFO - Finished export of dev_seen predictions
21/02/2021 12:15:38 AM : INFO - Optimal threshold on validation dataset: 0.5000 (accuracy=64.40%)
21/02/2021 12:15:38 AM : INFO - Export and testing on test_seen...
21/02/2021 12:15:44 AM : INFO - Finished export of test predictions
