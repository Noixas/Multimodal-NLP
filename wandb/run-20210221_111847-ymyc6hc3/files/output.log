21/02/2021 11:18:48 AM : INFO - Data path checked..
21/02/2021 11:18:48 AM : INFO - Model save path checked..
21/02/2021 11:18:48 AM : INFO - config JSON path checked..

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Running training with the following parameters: 

21/02/2021 11:18:48 AM : INFO - Tensorboard Visualization path checked..
21/02/2021 11:18:48 AM : INFO - Cleaning Visualization path of older tensorboard files...

data_path : ./dataset
model_path : ./model_checkpoints
vis_path : ./vis_checkpoints
model_save_name : meme.pt
no_model_checkpoints : False
remove_checkpoints : False
config : config/uniter-base.json
feature_path : ./dataset/own_features
pretrained_model_file : uniter-base.pt
max_txt_len : 60
max_bb : 100
min_bb : 10
num_bb : 36
optimizer : adam
loss_func : bce_logits
optimize_for : aucroc
scheduler : warmup_cosine
beta1 : 0.9
beta2 : 0.999
batch_size : 16
num_workers : 0
gradient_accumulation : 2
max_grad_norm : 5
pos_wt : 1
lr : 3e-05
warmup_steps : 500
weight_decay : 0.001
max_epoch : 30
lr_decay_step : 3
lr_decay_factor : 0.8
patience : 5.0
early_stop_thresh : 0.001
seed : 43
log_every : 2000
fc_dim : 64
dropout : 0.2
filter_text : True
normalize_img : True
train_filename : train.jsonl
upsample_multiplier : 3
device : cuda
n_classes : 1

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
filter text True
Confounders upsampled by 3 times. 
 From 750  samples to 2250
Saved confounder samples to: 
./dataset/train_upsampled_confounders_3x_times.jsonl
Loaded dataset contains  10750 samples
filter text True
Loaded dataset contains  500 samples
filter text True
Loaded dataset contains  1000 samples
21/02/2021 11:18:57 AM : INFO - Using pretrained UNITER base model ./model_checkpoints/uniter-base.pt
21/02/2021 11:18:57 AM : INFO - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

MemeUniter
MemeUniter(
  (uniter_model): UniterModel(
    (embeddings): UniterTextEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (img_embeddings): UniterImageEmbeddings(
      (img_linear): Linear(in_features=2048, out_features=768, bias=True)
      (img_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_linear): Linear(in_features=7, out_features=768, bias=True)
      (mask_embedding): Embedding(2, 2048, padding_idx=0)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): UniterEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (linear_1): Linear(in_features=768, out_features=384, bias=True)
  (tanh): Tanh()
  (linear_2): Linear(in_features=384, out_features=1, bias=True)
)


====================================================================================================
					 Training Network
====================================================================================================

Beginning training at:  2021-02-21 11:19:00.672614 


Epoch: 1/30,            
train_loss = 0.5987,  train_acc = 0.7166,  train_prec = 0.0288,  train_recall = 0.4307,  train_f1 = 0.0540,  train_aucroc = 0.5543,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.7185,  eval_acc = 0.5680,  eval_prec = 0.2065,  eval_recall = 0.7183,  eval_f1 = 0.3208,  eval_aucroc = 0.6110,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002016
Elapsed Time:  00:03:26.2421/02/2021 11:22:26 AM : INFO - New High Score! Saving model...

21/02/2021 11:22:28 AM : INFO - current patience: 0

Epoch: 2/30,            
train_loss = 0.4707,  train_acc = 0.7830,  train_prec = 0.4445,  train_recall = 0.6717,  train_f1 = 0.5350,  train_aucroc = 0.7965,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.6770,  eval_acc = 0.6440,  eval_prec = 0.4615,  eval_recall = 0.7170,  eval_f1 = 0.5616,  eval_aucroc = 0.7439,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002999
Elapsed Time:  00:06:46.4721/02/2021 11:25:47 AM : INFO - New High Score! Saving model...

21/02/2021 11:25:48 AM : INFO - current patience: 0

Epoch: 3/30,            
train_loss = 0.2876,  train_acc = 0.8870,  train_prec = 0.7622,  train_recall = 0.8224,  train_f1 = 0.7911,  train_aucroc = 0.9311,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.8098,  eval_acc = 0.6900,  eval_prec = 0.5385,  eval_recall = 0.7644,  eval_f1 = 0.6318,  eval_aucroc = 0.7604,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002995
Elapsed Time:  00:10:07.3221/02/2021 11:29:07 AM : INFO - New High Score! Saving model...

21/02/2021 11:29:09 AM : INFO - current patience: 0
21/02/2021 11:32:28 AM : INFO - current patience: 1

Epoch: 4/30,            
train_loss = 0.1532,  train_acc = 0.9468,  train_prec = 0.8970,  train_recall = 0.9121,  train_f1 = 0.9045,  train_aucroc = 0.9793,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.8463,  eval_acc = 0.7020,  eval_prec = 0.5668,  eval_recall = 0.7692,  eval_f1 = 0.6527,  eval_aucroc = 0.7532,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002986
Elapsed Time:  00:13:27.55

Epoch: 5/30,            
train_loss = 0.0968,  train_acc = 0.9688,  train_prec = 0.9371,  train_recall = 0.9512,  train_f1 = 0.9441,  train_aucroc = 0.9904,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3333,  eval_acc = 0.6700,  eval_prec = 0.4332,  eval_recall = 0.8106,  eval_f1 = 0.5646,  eval_aucroc = 0.7576,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002973
Elapsed Time:  00:16:46.6121/02/2021 11:35:47 AM : INFO - current patience: 2


Epoch: 6/30,            
train_loss = 0.0675,  train_acc = 0.9785,  train_prec = 0.9566,  train_recall = 0.9665,  train_f1 = 0.9615,  train_aucroc = 0.9953,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3240,  eval_acc = 0.7060,  eval_prec = 0.5628,  eval_recall = 0.7809,  eval_f1 = 0.6541,  eval_aucroc = 0.7643,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002956
Elapsed Time:  00:20:05.64
21/02/2021 11:39:06 AM : INFO - New High Score! Saving model...
21/02/2021 11:39:07 AM : INFO - current patience: 0

Epoch: 7/30,            
train_loss = 0.0669,  train_acc = 0.9775,  train_prec = 0.9583,  train_recall = 0.9614,  train_f1 = 0.9599,  train_aucroc = 0.9957,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3294,  eval_acc = 0.6740,  eval_prec = 0.5142,  eval_recall = 0.7471,  eval_f1 = 0.6091,  eval_aucroc = 0.7740,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002935
Elapsed Time:  00:23:30.1021/02/2021 11:42:30 AM : INFO - New High Score! Saving model...

21/02/2021 11:42:32 AM : INFO - current patience: 0

Epoch: 8/30,            
train_loss = 0.0615,  train_acc = 0.9787,  train_prec = 0.9626,  train_recall = 0.9616,  train_f1 = 0.9621,  train_aucroc = 0.9967,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.7957,  eval_acc = 0.6540,  eval_prec = 0.3887,  eval_recall = 0.8136,  eval_f1 = 0.5260,  eval_aucroc = 0.7455,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002909
Elapsed Time:  00:26:51.6321/02/2021 11:45:52 AM : INFO - current patience: 1


Epoch: 9/30,            
train_loss = 0.0598,  train_acc = 0.9816,  train_prec = 0.9646,  train_recall = 0.9697,  train_f1 = 0.9671,  train_aucroc = 0.9966,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4713,  eval_acc = 0.6520,  eval_prec = 0.4251,  eval_recall = 0.7664,  eval_f1 = 0.5469,  eval_aucroc = 0.7650,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002880
Elapsed Time:  00:30:13.5721/02/2021 11:49:14 AM : INFO - current patience: 2


Epoch: 10/30,            
train_loss = 0.0653,  train_acc = 0.9787,  train_prec = 0.9566,  train_recall = 0.9672,  train_f1 = 0.9619,  train_aucroc = 0.9958,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.2439,  eval_acc = 0.6880,  eval_prec = 0.5263,  eval_recall = 0.7692,  eval_f1 = 0.6250,  eval_aucroc = 0.7653,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002846
Elapsed Time:  00:33:33.7221/02/2021 11:52:34 AM : INFO - current patience: 3

21/02/2021 11:55:47 AM : INFO - current patience: 4

Epoch: 11/30,            
train_loss = 0.0490,  train_acc = 0.9833,  train_prec = 0.9679,  train_recall = 0.9727,  train_f1 = 0.9703,  train_aucroc = 0.9979,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6074,  eval_acc = 0.6480,  eval_prec = 0.4211,  eval_recall = 0.7591,  eval_f1 = 0.5417,  eval_aucroc = 0.7484,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002809
Elapsed Time:  00:36:46.45

Epoch: 12/30,            
train_loss = 0.0546,  train_acc = 0.9832,  train_prec = 0.9672,  train_recall = 0.9727,  train_f1 = 0.9699,  train_aucroc = 0.9974,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3750,  eval_acc = 0.6740,  eval_prec = 0.4372,  eval_recall = 0.8182,  eval_f1 = 0.5699,  eval_aucroc = 0.7536,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002767
Elapsed Time:  00:40:02.8821/02/2021 11:59:03 AM : INFO - current patience: 5


----------------------------------------------------------------------------------------------------

--------------------------------------------------
Best Validation scores:
--------------------------------------------------

Val accuracy of best model = 67.400
Val AUC-ROC of best model = 77.405
Val precision of best model = 51.417
Val recall of best model = 74.706
Val f1 of best model = 60.911

--------------------------------------------------
		Evaluating on test set
--------------------------------------------------
21/02/2021 11:59:03 AM : INFO - Training terminated early because the Validation aucroc did not improve for  5.0  epochs
21/02/2021 11:59:03 AM : INFO - Using UNITER model ./model_checkpoints/meme.pt
21/02/2021 11:59:04 AM : INFO - Exporting dev_seen predictions...
21/02/2021 11:59:07 AM : INFO - Finished export of dev_seen predictions
21/02/2021 11:59:07 AM : INFO - Optimal threshold on validation dataset: 0.5000 (accuracy=67.40%)
21/02/2021 11:59:07 AM : INFO - Export and testing on test_seen...
21/02/2021 11:59:13 AM : INFO - Finished export of test predictions
