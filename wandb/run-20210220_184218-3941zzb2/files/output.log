20/02/2021 06:42:19 PM : INFO - Data path checked..

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Running training with the following parameters: 
20/02/2021 06:42:19 PM : INFO - Model save path checked..
20/02/2021 06:42:19 PM : INFO - config JSON path checked..
20/02/2021 06:42:19 PM : INFO - Tensorboard Visualization path checked..
20/02/2021 06:42:19 PM : INFO - Cleaning Visualization path of older tensorboard files...


data_path : ./dataset
model_path : ./model_checkpoints
vis_path : ./vis_checkpoints
model_save_name : meme.pt
no_model_checkpoints : False
remove_checkpoints : False
config : config/uniter-base.json
feature_path : ./dataset/own_features
pretrained_model_file : uniter-base.pt
max_txt_len : 60
max_bb : 100
min_bb : 10
num_bb : 36
optimizer : adam
loss_func : bce_logits
optimize_for : aucroc
scheduler : warmup_cosine
beta1 : 0.9
beta2 : 0.999
batch_size : 16
num_workers : 0
gradient_accumulation : 2
max_grad_norm : 5
pos_wt : 1
lr : 3e-05
warmup_steps : 500
weight_decay : 0.001
max_epoch : 30
lr_decay_step : 3
lr_decay_factor : 0.8
patience : 5.0
early_stop_thresh : 0.001
seed : 43
log_every : 2000
fc_dim : 64
dropout : 0.2
filter_text : True
normalize_img : True
device : cuda
n_classes : 1

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
filter text True
filter text True
filter text True
20/02/2021 06:42:26 PM : INFO - Using pretrained UNITER base model ./model_checkpoints/uniter-base.pt
20/02/2021 06:42:26 PM : INFO - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

MemeUniter
MemeUniter(
  (uniter_model): UniterModel(
    (embeddings): UniterTextEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (img_embeddings): UniterImageEmbeddings(
      (img_linear): Linear(in_features=2048, out_features=768, bias=True)
      (img_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (pos_linear): Linear(in_features=7, out_features=768, bias=True)
      (mask_embedding): Embedding(2, 2048, padding_idx=0)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): UniterEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (linear): Linear(in_features=768, out_features=1, bias=True)
)


====================================================================================================
					 Training Network
====================================================================================================

Beginning training at:  2021-02-20 18:42:29.739243 


Epoch: 1/30,            
train_loss = 0.6298,  train_acc = 0.6564,  train_prec = 0.1461,  train_recall = 0.5625,  train_f1 = 0.2319,  train_aucroc = 0.6161,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.6939,  eval_acc = 0.5800,  eval_prec = 0.2794,  eval_recall = 0.6832,  eval_f1 = 0.3966,  eval_aucroc = 0.6537,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00001596
Elapsed Time:  00:02:44.3520/02/2021 06:45:14 PM : INFO - New High Score! Saving model...

20/02/2021 06:45:15 PM : INFO - current patience: 0

Epoch: 2/30,            
train_loss = 0.5555,  train_acc = 0.7213,  train_prec = 0.4124,  train_recall = 0.6766,  train_f1 = 0.5125,  train_aucroc = 0.7491,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.7015,  eval_acc = 0.6080,  eval_prec = 0.3198,  eval_recall = 0.7383,  eval_f1 = 0.4463,  eval_aucroc = 0.7178,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00003000
Elapsed Time:  00:05:38.4620/02/2021 06:48:08 PM : INFO - New High Score! Saving model...

20/02/2021 06:48:09 PM : INFO - current patience: 0

Epoch: 3/30,            
train_loss = 0.4201,  train_acc = 0.8164,  train_prec = 0.6959,  train_recall = 0.7657,  train_f1 = 0.7291,  train_aucroc = 0.8724,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.8558,  eval_acc = 0.6220,  eval_prec = 0.2794,  eval_recall = 0.8625,  eval_f1 = 0.4220,  eval_aucroc = 0.7522,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002997
Elapsed Time:  00:08:22.75
20/02/2021 06:50:52 PM : INFO - New High Score! Saving model...
20/02/2021 06:50:53 PM : INFO - current patience: 0

Epoch: 4/30,            
train_loss = 0.2553,  train_acc = 0.9025,  train_prec = 0.8529,  train_recall = 0.8699,  train_f1 = 0.8613,  train_aucroc = 0.9540,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 0.7936,  eval_acc = 0.6680,  eval_prec = 0.4413,  eval_recall = 0.7956,  eval_f1 = 0.5677,  eval_aucroc = 0.7497,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002990
Elapsed Time:  00:11:09.9120/02/2021 06:53:39 PM : INFO - current patience: 1


Epoch: 5/30,            
train_loss = 0.1581,  train_acc = 0.9446,  train_prec = 0.9218,  train_recall = 0.9221,  train_f1 = 0.9220,  train_aucroc = 0.9820,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.0352,  eval_acc = 0.6820,  eval_prec = 0.4575,  eval_recall = 0.8188,  eval_f1 = 0.5870,  eval_aucroc = 0.7570,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002979
Elapsed Time:  00:13:59.2320/02/2021 06:56:28 PM : INFO - New High Score! Saving model...

20/02/2021 06:56:30 PM : INFO - current patience: 0
20/02/2021 06:59:04 PM : INFO - current patience: 1

Epoch: 6/30,            
train_loss = 0.1090,  train_acc = 0.9648,  train_prec = 0.9503,  train_recall = 0.9506,  train_f1 = 0.9505,  train_aucroc = 0.9898,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.0776,  eval_acc = 0.6960,  eval_prec = 0.5709,  eval_recall = 0.7540,  eval_f1 = 0.6498,  eval_aucroc = 0.7484,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002963
Elapsed Time:  00:16:34.42
20/02/2021 07:01:41 PM : INFO - current patience: 2

Epoch: 7/30,            
train_loss = 0.0802,  train_acc = 0.9749,  train_prec = 0.9636,  train_recall = 0.9658,  train_f1 = 0.9647,  train_aucroc = 0.9943,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.2300,  eval_acc = 0.6860,  eval_prec = 0.4737,  eval_recall = 0.8125,  eval_f1 = 0.5985,  eval_aucroc = 0.7408,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002943
Elapsed Time:  00:19:11.84

Epoch: 8/30,            
train_loss = 0.0733,  train_acc = 0.9767,  train_prec = 0.9649,  train_recall = 0.9694,  train_f1 = 0.9671,  train_aucroc = 0.9945,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3713,  eval_acc = 0.6780,  eval_prec = 0.4980,  eval_recall = 0.7688,  eval_f1 = 0.6044,  eval_aucroc = 0.7349,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002919
Elapsed Time:  00:21:53.0320/02/2021 07:04:22 PM : INFO - current patience: 3


Epoch: 9/30,            
train_loss = 0.0643,  train_acc = 0.9793,  train_prec = 0.9682,  train_recall = 0.9734,  train_f1 = 0.9708,  train_aucroc = 0.9963,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6583,  eval_acc = 0.6600,  eval_prec = 0.4494,  eval_recall = 0.7655,  eval_f1 = 0.5663,  eval_aucroc = 0.7004,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002890
Elapsed Time:  00:24:28.1520/02/2021 07:06:57 PM : INFO - current patience: 4

20/02/2021 07:09:34 PM : INFO - New High Score! Saving model...

Epoch: 10/30,            
train_loss = 0.0733,  train_acc = 0.9773,  train_prec = 0.9662,  train_recall = 0.9697,  train_f1 = 0.9680,  train_aucroc = 0.9956,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.1413,  eval_acc = 0.6760,  eval_prec = 0.5385,  eval_recall = 0.7348,  eval_f1 = 0.6215,  eval_aucroc = 0.7620,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002858
Elapsed Time:  00:27:04.65
20/02/2021 07:09:35 PM : INFO - current patience: 0
20/02/2021 07:12:08 PM : INFO - current patience: 1

Epoch: 11/30,            
train_loss = 0.0608,  train_acc = 0.9805,  train_prec = 0.9672,  train_recall = 0.9776,  train_f1 = 0.9724,  train_aucroc = 0.9966,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6520,  eval_acc = 0.6580,  eval_prec = 0.4575,  eval_recall = 0.7533,  eval_f1 = 0.5693,  eval_aucroc = 0.7448,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002821
Elapsed Time:  00:29:38.65

Epoch: 12/30,            
train_loss = 0.0637,  train_acc = 0.9799,  train_prec = 0.9675,  train_recall = 0.9756,  train_f1 = 0.9716,  train_aucroc = 0.9967,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.3083,  eval_acc = 0.6500,  eval_prec = 0.4291,  eval_recall = 0.7571,  eval_f1 = 0.5478,  eval_aucroc = 0.7339,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002781
Elapsed Time:  00:32:10.2220/02/2021 07:14:39 PM : INFO - current patience: 2


Epoch: 13/30,            
train_loss = 0.0591,  train_acc = 0.9812,  train_prec = 0.9712,  train_recall = 0.9757,  train_f1 = 0.9734,  train_aucroc = 0.9970,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.7675,  eval_acc = 0.6540,  eval_prec = 0.4332,  eval_recall = 0.7643,  eval_f1 = 0.5530,  eval_aucroc = 0.7347,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002737
Elapsed Time:  00:34:44.0320/02/2021 07:17:13 PM : INFO - current patience: 3


Epoch: 14/30,            
train_loss = 0.0564,  train_acc = 0.9801,  train_prec = 0.9715,  train_recall = 0.9725,  train_f1 = 0.9720,  train_aucroc = 0.9980,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.4632,  eval_acc = 0.6500,  eval_prec = 0.5223,  eval_recall = 0.6935,  eval_f1 = 0.5958,  eval_aucroc = 0.7400,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002689
Elapsed Time:  00:37:22.1620/02/2021 07:19:51 PM : INFO - current patience: 4


Epoch: 15/30,            
train_loss = 0.0539,  train_acc = 0.9806,  train_prec = 0.9748,  train_recall = 0.9706,  train_f1 = 0.9727,  train_aucroc = 0.9977,  train_opt_accuracy = -1.0000,  train_threshold = -1.0000            
eval_loss = 1.6110,  eval_acc = 0.6880,  eval_prec = 0.4980,  eval_recall = 0.7935,  eval_f1 = 0.6119,  eval_aucroc = 0.7577,  eval_opt_accuracy = -1.0000,  eval_threshold = -1.0000                
lr  =  0.00002638
Elapsed Time:  00:39:59.7520/02/2021 07:22:29 PM : INFO - current patience: 5


----------------------------------------------------------------------------------------------------

--------------------------------------------------
Best Validation scores:
--------------------------------------------------

Val accuracy of best model = 67.600
Val AUC-ROC of best model = 76.197
Val precision of best model = 53.846
Val recall of best model = 73.481
Val f1 of best model = 62.150

--------------------------------------------------
		Evaluating on test set
--------------------------------------------------
20/02/2021 07:22:29 PM : INFO - Training terminated early because the Validation aucroc did not improve for  5.0  epochs
20/02/2021 07:22:29 PM : INFO - Using UNITER model ./model_checkpoints/meme.pt
20/02/2021 07:22:30 PM : INFO - Exporting dev_seen predictions...
20/02/2021 07:22:33 PM : INFO - Finished export of dev_seen predictions
20/02/2021 07:22:33 PM : INFO - Optimal threshold on validation dataset: 0.5000 (accuracy=67.60%)
20/02/2021 07:22:33 PM : INFO - Export and testing on test_seen...
20/02/2021 07:22:39 PM : INFO - Finished export of test predictions
